# üçî FoodReview Insights Agent

<div align="center">

[![Portugu√™s](https://img.shields.io/badge/Ler_em-Portugu√™s-green?style=for-the-badge)](./README.md)
![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![LangGraph](https://img.shields.io/badge/AI-LangGraph-orange?style=for-the-badge)
![Llama 3](https://img.shields.io/badge/Model-Llama_3.3_70B-blueviolet?style=for-the-badge)

**An Autonomous AI Agent capable of extracting strategic insights from unstructured customer reviews.**

<br />
<br />

<img src="./assets/preview.png" alt="FoodReview AI Chat" width="100%" style="border-radius: 10px; border: 1px solid #333;">

<br />
<br />



</div>

---

## üöÄ About the Project

Built as a portfolio project for the **GenAI Engineering** track, this application simulates an intelligent analyst for restaurant owners.

Unlike simple RAG systems, this agent uses a **Reasoning Engine (ReAct)** powered by **LangGraph** to:
1.  **Understand Context:** Interprets complex queries in natural language (PT-BR).
2.  **Tool Use:** Decides when to query the Vector Database vs. using general knowledge.
3.  **Handle Noisy Data:** Analyzes sentiment from realistic, messy reviews (slang, typos, caps lock) generated by a custom Synthetic Data Pipeline.

### üèóÔ∏è Architecture

* **Brain:** Llama 3.3 70B (via Groq API)
* **Orchestration:** LangGraph (State-of-the-art agentic framework)
* **Memory (RAG):** ChromaDB + HuggingFace Embeddings (`all-MiniLM-L6-v2`)
* **Backend:** FastAPI (Python)
* **Frontend:** Next.js 15 + Tailwind CSS (Cyberpunk Terminal UI)
* **Data Engineering:** Synthetic Data Pipeline simulating Brazilian delivery scenarios.

---

## üõ†Ô∏è How to Run Locally

### 1. Clone and Setup
```bash
git clone https://github.com/josevbrito/food-review-agent.git
cd food-review-agent

# Create Virtual Environment
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install Dependencies
pip install -r backend/requirements.txt
````

### 2\. Configure Environment

Create a `backend/.env` file based on `backend/.env.example`:

```ini
GROQ_API_KEY=gsk_your_key_here
```

### 3\. Generate Data & Start Backend

This script will generate fresh synthetic data using Llama 3 (simulating "angry customers", "gen z", etc.) and populate the Vector DB.

```bash
# From project root
cd backend
python app/scripts/generate_synthetic_data.py
uvicorn app.main:app --reload
```

### 4\. Start Frontend

Open a new terminal:

```bash
cd frontend
npm install
npm run dev
```

Access the terminal interface at `http://localhost:3000`.

-----

## üß™ Testing the Agent

Try asking these questions to test the agent's reasoning capabilities:

  * *"O que falam sobre a entrega?"* (Sentiment Analysis)
  * *"Tem reclama√ß√µes sobre o Sushi?"* (Specific Retrieval)
  * *"O pessoal est√° bravo?"* (Context understanding of "Caps Lock" and slang)

-----

## üë®‚Äçüíª Author

**Jos√© Victor Brito Costa**
* Software Engineer & Data Scientist
* Focus: LLMOps, Agents, and Full Stack Development.

<div align="left"> 
  <a href="https://josevbrito.com" target="_blank">
    <img src="https://img.shields.io/badge/Portfolio-Visit_Site-00ff41?style=for-the-badge&logo=vercel&logoColor=black" alt="Portfolio">
  </a>
  <a href="https://www.linkedin.com/in/josevbrito" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin" alt="LinkedIn">
  </a>
</div>

<br />

> **If this project helped you or you liked the architecture, please give it a ‚≠êÔ∏è on GitHub!**